{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "2U5fVmvLYHB4",
    "outputId": "8dd7be2b-9b5e-412e-cff7-e39d4e3b781d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# ###### Comment out ########\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANTX7IKKdv7l"
   },
   "source": [
    "# Project: Sarcasm Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkRsRjpYdv7n"
   },
   "source": [
    "## Problem:\n",
    "The purpose of this project is to get you familiar with word2vec, logistic regression, k\n",
    "nearest neighbor and perceptron classification. You are given with News Headlines Dataset\n",
    "for Sarcasm Detection that contains news headlines labeled for sarcasm. Your task is to\n",
    "implement a sarcasm detector for the news headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZlu6nn9dv7q"
   },
   "source": [
    "## Dataset:\n",
    "The data set contains 28,616 headlines which are divided into two sets:\n",
    "<ul>\n",
    "    <li>train: 22,892 headlines </li>\n",
    "    <li>test: 5,724 headlines</li>\n",
    "</ul>\n",
    "The format of the files is &lt;label>,&lt;headline>. Where &lt;label> is 1 if the headline is sarcastic\n",
    "and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84-az6r3dv7t"
   },
   "source": [
    "## 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVnfhROEdv7x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import math \n",
    "import pandas as pd\n",
    "import string\n",
    "# !pip3 install gensim\n",
    "from gensim import corpora, models, similarities \n",
    "from gensim.models import KeyedVectors\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "import operator\n",
    "import time\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "1ULPEMxvdama",
    "outputId": "13db8fc2-f869-482b-e22b-9408c2a76e78"
   },
   "outputs": [],
   "source": [
    "##### Change this to your local path ##### \n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3d6T3rr1dv8L"
   },
   "outputs": [],
   "source": [
    "# Dataset is divided into train and test data which is then further divided into X and Y\n",
    "\n",
    "column_names = [\"Label\", \"Headline\"]\n",
    "train = pd.read_csv (r'train.txt', names = column_names)\n",
    "test = pd.read_csv (r'test.txt', names = column_names)\n",
    "text_file = open(\"stopwords.txt\", \"r\")\n",
    "stopwords = text_file.read().split('\\n')\n",
    "\n",
    "X_train = train['Headline']\n",
    "X_test = test['Headline']\n",
    "Y_train = train['Label'] \n",
    "Y_test = test['Label'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xy35c9I3dv8W"
   },
   "source": [
    "## 2. Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hb6N28hdv8Y"
   },
   "source": [
    "### 2.1 Remove stop words and punctuation marks from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HV2RCI24dv8i"
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "def oheEncoding(data):\n",
    "    arr = []\n",
    "    for label in data:\n",
    "        if label == 1:\n",
    "            arr.append([0,1])\n",
    "        else:\n",
    "            arr.append([1,0])\n",
    "    arr = np.asarray(arr)\n",
    "    arr = pd.DataFrame(arr)\n",
    "    arr = arr.to_numpy()\n",
    "    return arr\n",
    "\n",
    "ytr = oheEncoding(Y_train)\n",
    "ytr_enc = Y_train\n",
    "yte = Y_test\n",
    "\n",
    "# Removing punctuationn from dataset\n",
    "def dataCleaning(data):\n",
    "    arr = []\n",
    "    for text in data:\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\W',' ',text)\n",
    "        text = re.sub(r'\\s+',' ',text)\n",
    "        arr.append(text)\n",
    "    arr = pd.DataFrame(arr, columns=[\"Headline\"])\n",
    "    return arr\n",
    "\n",
    "def xProcess(X_train, X_test, stopwords):\n",
    "    xtr = dataCleaning(X_train)\n",
    "    xte = dataCleaning(X_test)\n",
    "    \n",
    "    # Filtering out stop words\n",
    "    xtr['Headline'] = xtr['Headline'].str.split().apply(lambda x: [item for item in x if item not in stopwords])\n",
    "    xte['Headline'] = xte['Headline'].str.split().apply(lambda x: [item for item in x if item not in stopwords])\n",
    "    \n",
    "    return xtr, xte\n",
    "\n",
    "xtr, xte = xProcess(X_train, X_test, stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FazZugWNdv84"
   },
   "source": [
    "### 2.2 Represent the news headline as the average of all words in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5dZxrsK1dv85"
   },
   "outputs": [],
   "source": [
    "# Retrieving the vector representations of the words and then taking mean for each row\n",
    "def embedDf(df):\n",
    "    embedded = []\n",
    "    to_delete = []\n",
    "    for current, i in zip(df['Headline'], range(len(df['Headline']))):\n",
    "\n",
    "        # Checks if a word exists in our word2vec model and if number of words in a row is greater than 1\n",
    "        if all(i in word2vec.vocab for i in current) and len(current) > 1:\n",
    "            result = np.mean(word2vec[current], axis=0)    \n",
    "            embedded.append(result)\n",
    "        else:\n",
    "            to_delete.append(i)\n",
    "\n",
    "    embedded = pd.DataFrame(embedded)\n",
    "    embedded = embedded.to_numpy()\n",
    "    return embedded, to_delete\n",
    "\n",
    "# Removed enteries filtered out from the label dataset\n",
    "def remove_elements(my_list, to_del):\n",
    "    somelist = [i for j, i in enumerate(my_list) if j not in to_del]\n",
    "    return somelist\n",
    "\n",
    "vecxtr, del_ytr = embedDf(xtr)\n",
    "vecxte, del_yte = embedDf(xte)\n",
    "\n",
    "ytr = remove_elements(ytr, del_ytr)\n",
    "ytr_enc = remove_elements(ytr_enc, del_ytr)\n",
    "yte = remove_elements(yte, del_yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uW3CigrLdv9A"
   },
   "source": [
    "## 3. Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCBrA8Iddv9B"
   },
   "source": [
    "### 3.1 Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "NF7xrO5YBTEk",
    "outputId": "d86e5239-e4dc-442d-90e8-1208b6a0ef2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 24.25016975402832 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3Rc5Xnv8e8zN83oLtuSL5KJMRgT6oAxigmBkACBgBcBmuY00LQhkFP3ktAmK10pNF0hTZouThuSJqtZpJRA0lNCEiA0lFLAx21JWgqxDMYxGOMLNpavsiVZ1nU0M8/5Y2/JY3lky7ZGY0u/z1pa0t6z9+jZ2rZ+et937/2auyMiIjJSpNQFiIjIqUkBISIiBSkgRESkIAWEiIgUpIAQEZGCYqUuYDzNmDHD582bV+oyREROG6tXr97n7vWFXptUATFv3jxaWlpKXYaIyGnDzLaN9pq6mEREpCAFhIiIFKSAEBGRghQQIiJSkAJCREQKUkCIiEhBCggRESlIAQF8e+VGnn+zrdRliIicUhQQwHef38wvFBAiIodRQADxaITBbK7UZYiInFIUEIQBkdPMeiIi+RQQQCJqDGbUghARyVe0gDCzhWa2Ju+jy8w+a2ZfNrMdeeuXjbL/tWa2wcw2mdmdxaoTIB5TF5OIyEhFe5qru28AFgOYWRTYATwB3AZ8092/Ptq+4fbfAa4GWoFVZvaku79ejFqDMQh1MYmI5JuoLqargM3uPupjZUdYCmxy9y3ungZ+BNxYrOLi0QhptSBERA4zUQFxM/BI3vJnzGytmT1oZnUFtm8Etuctt4brjmBmy82sxcxa2tpO7FLVRNTUxSQiMkLRA8LMEsANwKPhqvuAswi6n3YB9xbarcC6gn1A7n6/uze7e3N9fcFJkY5Jl7mKiBxpIloQ1wEvu/seAHff4+5Zd88B/0DQnTRSKzA3b7kJ2FmsAuPRCIMZjUGIiOSbiIC4hbzuJTObnffarwPrCuyzClhgZmeGLZCbgSeLVWA8pjEIEZGRihoQZlZOcCXST/NW/7WZ/crM1gJXAJ8Lt51jZk8DuHsG+AzwLLAe+Im7v1asOjUGISJypKJd5grg7r3A9BHrfmeUbXcCy/KWnwaeLmZ9Q2IRjUGIiIykO6kZulFOYxAiIvkUEEA8aqT1qA0RkcMoIICELnMVETmCAoLgMteMnuYqInIYBQRD90GoBSEikk8BAcRjpvsgRERGUECgMQgRkUIUEARdTDmHrMYhRESGKSAIAgJQK0JEJI8CguA+CEDjECIieRQQQCIWtiB0JZOIyDAFBPldTBqDEBEZooBAYxAiIoUoINAYhIhIIQoI1IIQESlEAUFeQGjaURGRYQoI1MUkIlJI0WaUM7OFwI/zVs0HvgQ0Ah8G0sBm4DZ37yyw/1bgIJAFMu7eXKxaE2ELIqOAEBEZVrQWhLtvcPfF7r4YuAjoBZ4AVgCL3P184E3grqO8zRXhexQtHCCYUQ50mauISL6J6mK6Ctjs7tvc/Tl3z4TrXwSaJqiGUWmQWkTkSBMVEDcDjxRYfzvwb6Ps48BzZrbazJaP9sZmttzMWsyspa2t7YSK0xiEiMiRih4QZpYAbgAeHbH+i0AGeHiUXS919yXAdcCnzezyQhu5+/3u3uzuzfX19SdUY0ItCBGRI0xEC+I64GV33zO0wsxuBa4HPu7uBTv+3X1n+HkvwdjF0mIVqC4mEZEjTURA3EJe95KZXQv8KXCDu/cW2sHMKsysauhr4BpgXbEKHB6k1n0QIiLDihoQZlYOXA38NG/13wFVwAozW2Nm3w23nWNmT4fbzAT+y8xeBX4J/Ku7P1OsOjUGISJypKLdBwEQthCmj1h39ijb7gSWhV9vAS4oZm35NAYhInIk3UmNxiBERApRQACxsItJN8qJiByigADikeDHkNaMciIiwxQQQCRixCKmLiYRkTwKiFA8GlFAiIjkUUCE4lHTGISISB4FRCgRUwtCRCSfAiKkLiYRkcMpIEJBQKiLSURkiAIiFI+aHrUhIpJHARGKRyMM6j4IEZFhCoiQBqlFRA6ngAhpDEJE5HAKiFA8anrUhohIHgVEqCwWpT+TLXUZIiKnDAVEqDwRpTetgBARGaKACKUSUfoUECIiw4oWEGa2MJxSdOijy8w+a2bTzGyFmW0MP9eNsv+t4TYbzezWYtU5JGhBZIr9bUREThtFCwh33+Dui919MXAR0As8AdwJrHT3BcDKcPkwZjYNuBu4GFgK3D1akIyX8kRMXUwiInkmqovpKmCzu28DbgR+EK7/AXBTge0/BKxw93Z37wBWANcWs8BUPMpAJkc2p0tdRURg4gLiZuCR8OuZ7r4LIPzcUGD7RmB73nJruO4IZrbczFrMrKWtre2ECyxPRAHoG1QrQkQEJiAgzCwB3AA8ejy7FVhX8E97d7/f3Zvdvbm+vv5ESgQOBYTGIUREAhPRgrgOeNnd94TLe8xsNkD4eW+BfVqBuXnLTcDOYhaZSsQAdCWTiEhoIgLiFg51LwE8CQxdlXQr8LMC+zwLXGNmdeHg9DXhuqI51IJQQIiIQJEDwszKgauBn+atvge42sw2hq/dE27bbGYPALh7O/BVYFX48ZVwXdGkNAYhInKYWDHf3N17gekj1u0nuKpp5LYtwP/OW34QeLCY9eUrj4cBoRaEiAigO6mHlYdjEOpiEhEJKCBCKV3FJCJyGAVEaPg+CLUgREQABcQwXcUkInI4BURIVzGJiBxOARFKRCNEI6YxCBGRkAIiZGaUxzVpkIjIEAVEnqQmDRIRGaaAyKNpR0VEDlFA5Empi0lEZJgCIk95IkrfoAapRURAAXEYTTsqInKIAiJPSoPUIiLDFBB5NEgtInKIAiKPAkJE5BAFRJ5UPEaf7qQWEQEUEIcpT0TpHczi7qUuRUSk5Io6o5yZ1QIPAIsAB24HPgssDDepBTrdfXGBfbcCB4EskHH35mLWCsEgtTsMZHIkwxnmRESmqqIGBPAt4Bl3/6iZJYByd//Y0Itmdi9w4Cj7X+Hu+4pc47D8R34rIERkqitaQJhZNXA58EkAd08D6bzXDfhN4Mpi1XC8yvXIbxGRYcUcg5gPtAEPmdkrZvaAmVXkvf4+YI+7bxxlfweeM7PVZrZ8tG9iZsvNrMXMWtra2k6q4FQ4L7UGqkVEihsQMWAJcJ+7Xwj0AHfmvX4L8MhR9r/U3ZcA1wGfNrPLC23k7ve7e7O7N9fX159UweVxzSonIjKkmAHRCrS6+0vh8mMEgYGZxYCPAD8ebWd33xl+3gs8ASwtYq2Aph0VEclXtIBw993AdjMbumLpKuD18OsPAm+4e2uhfc2swsyqhr4GrgHWFavWIcPTjiogRESKfhXTHcDD4RVMW4DbwvU3M6J7yczmAA+4+zJgJvBEMI5NDPihuz9T5FopD8cg1IIQESlyQLj7GuCI+xfc/ZMF1u0EloVfbwEuKGZthaSGxyA0SC0iMqYuJjP7X2NZd7pL6TJXEZFhYx2DuGuM605rGqQWETnkqF1MZnYdQbdPo5l9O++lamDS9cOkdJmriMiwY41B7ARagBuA1XnrDwKfK1ZRpRKJGMl4RDfKiYhwjIBw91eBV83sh+4+CGBmdcBcd++YiAInmqYdFREJjHUMYoWZVZvZNOBVgsdnfKOIdZVMKq5pR0VEYOwBUePuXQR3Pz/k7hcR3Ow26WhWORGRwFgDImZmswmevvpUEespuaFJg0REprqxBsRXgGeBze6+yszmA6M9hfW0lkpENUgtIsIY76R290eBR/OWtwC/UayiSqk8EWNPV3+pyxARKbmx3kndZGZPmNleM9tjZo+bWVOxiyuFoAWhLiYRkbF2MT0EPAnMARqBfwnXTTrlcQ1Si4jA2AOi3t0fcvdM+PF94ORm5zlFVSZj9AxoDEJEZKwBsc/MftvMouHHbwP7i1lYqVSVxehOZ8jlvNSliIiU1FgD4naCS1x3A7uAj3JobodJpTIZwx1d6ioiU95YA+KrwK3uXu/uDQSB8eWiVVVCVck4AN396mYSkaltrAFxfv6zl9y9HbiwOCWVVmVZcOVv98BgiSsRESmtsQZEJHxIHwDhM5mOeQ+FmdWa2WNm9oaZrTezS8zsy2a2w8zWhB/LRtn3WjPbYGabzOzOMdZ50mpSQQuio1cBISJT21inHL0XeMHMHgOcYDzia2PY71vAM+7+0XBe6nLgQ8A33f3ro+1kZlHgO8DVQCuwysyedPfXx1jvCWuoLgNgb9dAsb+ViMgpbax3Uv+jmbUAVwIGfORYv6zNrBq4HPhk+B5pIG1mY/mWS4FN4R3bmNmPgBuB4gdEVRKAvQd1N7WITG1jbUEQBsLx/IKeD7QRPBr8AoIJh/44fO0zZvYJgsmIPl9gbolGYHvecitw8XF87xNWVx4nHjX2HlQLQkSmtrGOQZyIGLAEuM/dLwR6gDuB+4CzgMUEl8zeW2DfQs2MgjcmmNlyM2sxs5a2traTLtrMaKhKqotJRKa8YgZEK9Dq7i+Fy48BS9x9j7tn3T0H/ANBd1KhfefmLTcRTH96BHe/392b3b25vn58bu6urypTF5OITHlFCwh33w1sN7OF4aqrgNfDeSWG/DqwrsDuq4AFZnZmOLh9M8GzoCZEQ1WZWhAiMuWNeQziBN0BPBz+kt9CcPf1t81sMUGX0Vbg9wDMbA7wgLsvc/eMmX2GYA6KKPCgu79W5FqHNVSXsWpr+0R9OxGRU1JRA8Ld1wDNI1b/zijb7gSW5S0/DTxdvOpGN7MqSUfvIAOZLGWxaClKEBEpuWKOQZy26quCeyH2d6dLXImISOkoIAqoDu+m7urX3dQiMnUpIAqoSgY9bwf1wD4RmcIUEAUMPdH1oFoQIjKFKSAKUAtCREQBUVB12ILo6lMLQkSmLgVEAdMqEsQixq4DuptaRKYuBUQB0YgxqybJjs6+UpciIlIyCohRNNam2KmAEJEpTAExisbaFDs6FBAiMnUpIEbRWJdid1c/6Uyu1KWIiJSEAmIU58ysIuewYffBUpciIlISCohRvHveNKIR4+l1u0pdiohISSggRjGrJsl5s6tZt+NAqUsRESkJBcRRzJ2mgWoRmboUEEfRWJtiR2cf7gWnwxYRmdQUEEfRWJtiIJOjrVvTj4rI1KOAOIqmunIAdTOJyJRU1IAws1oze8zM3jCz9WZ2iZn9Tbi81syeMLPaUfbdama/MrM1ZtZSzDpH01iXAtAjN0RkSip2C+JbwDPufi5wAbAeWAEscvfzgTeBu46y/xXuvtjdR85rPSGGAqJVLQgRmYKKFhBmVg1cDnwPwN3T7t7p7s+5+9BECy8CTcWq4WRVJ+NUJWPqYhKRKamYLYj5QBvwkJm9YmYPmFnFiG1uB/5tlP0deM7MVpvZ8tG+iZktN7MWM2tpa2sbn8rzNNam2HVAASEiU08xAyIGLAHuc/cLgR7gzqEXzeyLQAZ4eJT9L3X3JcB1wKfN7PJCG7n7/e7e7O7N9fX143oAMHSpq+aFEJGpp5gB0Qq0uvtL4fJjBIGBmd0KXA983Ee5ycDdd4af9wJPAEuLWOuo5uix3yIyRRUtINx9N7DdzBaGq64CXjeza4E/BW5w995C+5pZhZlVDX0NXAOsK1atR9NYl+JA3yDdA5qfWkSmlliR3/8O4GEzSwBbgNuAVUAZsMLMAF509983sznAA+6+DJgJPBG+HgN+6O7PFLnWgubUBlcy7ezs45yZVaUoQUSkJIoaEO6+Bhh5ierZo2y7E1gWfr2F4LLYkmusTQLBvRAKCBGZSnQn9TEMtSB0qauITDUKiGNoqEqSiEV4u73gcImIyKSlgDiGaMQ4c3oF3/uvt+hNa6BaRKYOBcQYXH7ODLI55yertpe6FBGRCaOAGIO7rnsnAC3bOkpciYjIxFFAjEEkYtyy9Az+3/o9DGZzpS5HRGRCKCDGaOmZdfQP5ti6r6fUpYiITAgFxBgN3QOxYc/BElciIjIxFBBjdFZ9JdGIsWG3AkJEpgYFxBgl41HmTS9XQIjIlKGAOA7nzqpWF5OITBkKiONwzswq3m7v1Q1zIjIlKCCOw8JZlbjD5r26kklEJj8FxHFoqisHgie7iohMdgqI4zC7Jnj093ef31ziSkREik8BcRymVSQAWLO9k4zuqBaRSU4BcRzMjO/81hIAXti8v8TViIgUV1EDwsxqzewxM3vDzNab2SVmNs3MVpjZxvBz3Sj73hpus9HMbi1mncfjsrNnAPCJB39Ja4fmiBCRyavYLYhvAc+4+7kEU4iuB+4EVrr7AmBluHwYM5sG3A1cDCwF7h4tSCZaTXmc333fmQD81dPrS1yNiEjxFC0gzKwauBz4HoC7p929E7gR+EG42Q+Amwrs/iFghbu3u3sHsAK4tli1Hq/PX7OQBQ2VvLr9gMYiRGTSKmYLYj7QBjxkZq+Y2QNmVgHMdPddAOHnhgL7NgL5s/O0huuOYGbLzazFzFra2trG9whGkYxH+aOrFrCjs48PfP0/OdA7OCHfV0RkIhUzIGLAEuA+d78Q6KFAd9IorMA6L7Shu9/v7s3u3lxfX39ilZ6AD18wh7uuO5fWjj6efX33hH1fEZGJUsyAaAVa3f2lcPkxgsDYY2azAcLPe0fZd27echOws4i1npDffd98zm6o5K+eXk9HT7rU5YiIjKuiBYS77wa2m9nCcNVVwOvAk8DQVUm3Aj8rsPuzwDVmVhcOTl8TrjulRCLGX960iM7eQS786gr60tlSlyQiMm6KfRXTHcDDZrYWWAz8FXAPcLWZbQSuDpcxs2YzewDA3duBrwKrwo+vhOtOOe+ZP51L5k8H4Cct24+xtYjI6cPcC3btn5aam5u9paVlwr/vYDbHeV96hisWNnD/J5on/PuLiJwoM1vt7gV/celO6nEQj0b48PlzePntTiZT4IrI1KaAGCdL3lHHvu4B3tqnR4GLyOSggBgnV57bQCxiPP5ya6lLEREZFwqIcTKnNsWixho9xE9EJg0FxDi6btEsXnm7k8dWqxUhIqc/BcQ4umHxHAD+5NFXS1yJiMjJU0CMo9k1KX6zuQmAXQc0LamInN4UEOPsjisXEDH4wQvbSl2KiMhJiZW6gMlm7rRy3regnu8+v5nHX27lDz9wFhWJGG/uOcifX39eqcsTERkzBUQR/P77z2LN9k7aDg7wF//y+vD6RY013HRhwaeWi4icchQQRXDJWdNZ86Wr+cXGfaxcv4doJMJLb+3nC4+vZX59Bec31Za6RBGRY9KzmCZIa0cvN33nv5lRWcaTn7mMREzDPyJSenoW0ymgqa6cv7xpEW/sPsh771nJH/zTajbt7S51WSIio1JATKBrF83mr3/jfPZ1p/m3dbv54DeeZ9eBPl55u4M/fWwtb+zuKnWJIiLD1MVUAu7OF/95HT986e3D1r+rsYbH/+C96n4SkQlztC4mDVKXgJnxtZsWsWhODf/04jbev7CeWdVJ7n7yNX7rH17knFlVXHzmNG5crCueRKR01II4hXz+J68e8TTYqrIYixpruPLcBj512ZlEIlai6kRkMipZC8LMtgIHgSyQcfdmM/sxMDRPdS3Q6e6Lx7JvMWs9FXzpw+dx8fxpNNWl+O0HXiLncHAgw/9s2c//bNnPW/t7qE7Guf782SxqrCl1uSIyyRW1BRH+km92932jvH4vcMDdv3K8+xZyurcg8rk7G/YcZFp5gvqqMj750Cqef7MNgMqyGN/5+BLef049ALmcq2UhIifklByDMDMDfhO4slQ1nMrMjHNnVQ8vP/TJd/ONFW+yr3uAJ17Zwa0P/pL3zJ9GJuus39XFzUvP4K7rzqUnnaU6GSP48YqInLhityDeAjoAB/7e3e/Pe+1y4BujJdfR9h2x3XJgOcAZZ5xx0bZtk/8hefu6B/i7f9/E91/YSiIWIZ3JAdBYm2LvwX4Gs86ZMyr48PmzuWFxI2c3VDKQyWIYZsEc2kOef7ONn7RspzoZY2Awx3lzqrni3AbOqq8s1eGJyAQ6Wgui2AExx913mlkDsAK4w91/Hr52H7DJ3e893n1HM5m6mMZibWsnc2pTVCfj/OHDL/PSW/vJZJ3BbI5M7tB5nV2TZHdXP+6QiEVY3FTLObMq2bS3mxe3tBd870QsQk0qTnkiyqLGGgYzOd7a18N7z5rOF649l4oyXQAnMhmULCBGFPFloNvdv25mMWAHcJG7H3P6tfx9j7bdVAuIo9nZ2cfB/gzLvv0LsmFYNNamaKgu45W3OwGoLY+z7F2z+bNl7wRg674eNrd184uN+445K94NF8zhnbOruezsGbyrqYadnX08tXYnqUSMjzXP1b0cIqeJkgSEmVUAEXc/GH69AviKuz9jZtcCd7n7+49336N9TwXEkXYd6GPD7oO8b0E90XAg293pHshQlYwfc/9sztnfM8DuA/2k4lE2t3Xz1afW09mbpiedBWB6RYIDfYPDrZZfm1PN929bSkdvmnuf20BH7yC1qTiNdSk+fvE7GMhkOW92Nelsjr50ll0H+omYMasmSWVZ7LA6BzI5kvFokX46IlKqgJgPPBEuxoAfuvvXwte+D7zo7t/N234O8IC7LzvavkejgJg42ZzT0Zvm/p9vYUtbN/PrK/noRU2s3tbBl362jsHsoX9XMyoTmBltBweO+b7TKhKk4lEWzKxk674eMjnnH29fyoG+QWbXpKgtj7O5rZsdHX1cMLeWhqoyDciLnIRTootpIiggTg3rdhzgX3+1i1jEuHFxI/NnVBCJGP/+xh427O7mhc37OGdmFb9qPYBZME/G9MoEHT1ptrT1sPKNvTRUlbF3DIFSkYjyrqYaLj1rBrXlceqrklz0jjrqq8qO2DaXc7a193LGtHIGMlmyOT9mKyqb8+EWzdH0pbNsa+9hdk2KsliEJ9fspK17gLPqKzhnZhVnzqgg54zpvY7G3dnfk+a1nV28tvMAjbUp2g4O8PrOLrbu7wHgvDnVzK0rZzCbY3dXP/FohJ6BDLHooQsa6srjvLWvl2XvmsX1588hHjXS2eC1eCRCJGK4O5vbeohGjHQmRzxqJGIRugcyh9U0b3oFyXgUd6c3nWV7Ry/b2/voTWfY0dnH0K+Y+soyKpMxzqqvZN6McvZ3p3l1eyfJeJTKZIxczrlgbi1mMJh1dnT0sfdgP5v2dlOVjJOMR2jt6CObc+JRo7G2nKG/DWrL40yrSAzX1FiborIsuJpv78F+WrZ2HFbzQCZLTSpOXzrH9o5ekrEIDdXJ8GcMu7v6qSuPk4xHmV2T5J2zqzEL/j20dvSRG/F70zCa6lLs707TO5ghGYsyuzZ4v6gZsbwLQwazOXLuxCIRdnT00dbdz77uNA1VZezo7GN7+6H3L09Eefe8aUTM2NHZx2A2R1UyNvzvuyIRo6E6+LosdmItbQWEnLbW7+ripS37qatIsKern71dA9RVJJg/o4Jt7b28sauLn2/cR3tPenifVDzK7ZfN46J31PE/m/ez8o29RM3Y3tFL/2DwSzBiwaXEi+ZUM6OyjHg0whu7u+gbzNLdnyGVCP6z7etOc8HcWhbOrKQnnaUiEaWuPPhFtLmtm/qqMra39/HazgN09A6SiEYoi0U4OOKXaEUiymDOee9Z01nQUMkVCxuYUVVGdTLOrJrkYdv2D2bZ2xWEY9ad1o5e2nvSbG7r4Ue/fLtgcFaWxThvTjVRM1q2tQ+34MpiETI5Hw66mlQcA/b3pCmLRRgIA6MiER3uMqxKxqhOxukfzLI/7+c6mnjUaKhK0pPO0Nk7eMztJ0p1MkZVMs6+7oHh4yyFaMSYWVVGOpsjHo0MXzBiBuP163dGZRktf/7BE9pXASGTmrvT3pNm5fq91JbH+dbKjby289CTcc9vqqEsFiEZj3J+Uw3tPcEvsZ6BDG/t6+Ht9l5y7jTWplgws4psLkcm6/SkM/Sms8OD+ql4lL7B7PD7zq5J0j+YJRoxLnpHHdcumsXa1gP0D+a4cfEcLmiqZdXWdja3dbN+VxeG8V+b9rGnq/+wq8wg+Esx+MuS4YsKCllyRi1XvXMmCxoqufCMOtp70lQlY8yqTg7fLLm/e4CsO7WpBNGwJRAxwwmCESCTC9b9bM0ONu7tZm1rJ+9qrKWyLEprR99wfec31ZALW1p9g1nSmRyzapIMtYM6+wZZ83YnWXciFjzWvqkuxZzaFHXlCWZVJ0klouTCoOtNZ1nbeoADfYPEo8a7502jZyBLTzrDwf4Me7r6h491Tm2S2lSC+fUVDGRyuAfdlVXJOJ29aTrCMHKc1vbgr2uAgUyO1rAVk3WnLBbh2kWzaKgKgjibC8bgetIZppUnaKxL0ZfO0ps+dG5T8Sj9mSyD2Rzrdx08rK6Z1UkqEof/td43GIylVSVj1FeWsa97gK7+4I+E9p40nb2DdPUPUpWMMaOyjJpUnF0H+qhNJVjUWENNKjimxroUTXXlVIZXCb7d3sPGPcG0AHUVCWrL4+w60E9/WOvurn5601nKE1Fuu/TMUf/dHI0CQqacHZ19PLNuN+c31bDkjLqT6trpH8ySyTmVZTFWbW2nNhVndtiFcSJaO3p5YdN+HKerL8O29h76B4Oug4pEbPgX7VDNM6rKKItFmFWdZN6MihM+DpFCFBAiIlKQZpQTEZHjpoAQEZGCFBAiIlKQAkJERApSQIiISEEKCBERKUgBISIiBSkgRESkoEl1o5yZtQEnMqXcDGDMc19PEjrmqUHHPDWczDG/w93rC70wqQLiRJlZy2h3Ek5WOuapQcc8NRTrmNXFJCIiBSkgRESkIAVE4P5SF1ACOuapQcc8NRTlmDUGISIiBakFISIiBSkgRESkoCkfEGZ2rZltMLNNZnZnqesZL2Y218z+w8zWm9lrZvbH4fppZrbCzDaGn+vC9WZm3w5/DmvNbElpj+DEmFnUzF4xs6fC5TPN7KXweH9sZolwfVm4vCl8fV4p6z4ZZlZrZo+Z2Rvh+b5kMp9nM/tc+G96nZk9YmbJyXiezexBM9trZuvy1h33eTWzW8PtN5rZrcdTw5QOCDOLAt8BrgPOA24xs/NKW9W4yQCfd/d3Au8BPh0e253ASndfAKwMlyH4GUY9QEUAAAVySURBVCwIP5YD9018yePij4H1ecv/B/hmeLwdwKfC9Z8COtz9bOCb4Xanq28Bz7j7ucAFBMc/Kc+zmTUCfwQ0u/siIArczOQ8z98Hrh2x7rjOq5lNA+4GLgaWAncPhcqYuPuU/QAuAZ7NW74LuKvUdRXpWH8GXA1sAGaH62YDG8Kv/x64JW/74e1Olw+gKfxPcyXwFGAEd5fGRp5v4FngkvDrWLidlfoYTuCYq4G3RtY+Wc8z0AhsB6aF5+0p4EOT9TwD84B1J3pegVuAv89bf9h2x/qY0i0IDv1jG9IarptUwmb1hcBLwEx33wUQfm4IN5sMP4u/Bb4A5MLl6UCnu2fC5fxjGj7e8PUD4fanm/lAG/BQ2LX2gJlVMEnPs7vvAL4OvA3sIjhvq5n853nI8Z7XkzrfUz0grMC6SXXdr5lVAo8Dn3X3rqNtWmDdafOzMLPrgb3uvjp/dYFNfQyvnU5iwBLgPne/EOjhULdDIaf1cYfdIzcCZwJzgAqC7pWRJtt5PpbRjvOkjn+qB0QrMDdvuQnYWaJaxp2ZxQnC4WF3/2m4eo+ZzQ5fnw3sDdef7j+LS4EbzGwr8COCbqa/BWrNLBZuk39Mw8cbvl4DtE9kweOkFWh195fC5ccIAmOynucPAm+5e5u7DwI/Bd7L5D/PQ473vJ7U+Z7qAbEKWBBeAZEgGOx6ssQ1jQszM+B7wHp3/0beS08CQ1cy3EowNjG0/hPh1RDvAQ4MNWVPB+5+l7s3ufs8gvP47+7+ceA/gI+Gm4083qGfw0fD7U+7vyzdfTew3cwWhquuAl5nkp5ngq6l95hZefhvfOh4J/V5znO85/VZ4BozqwtbX9eE68am1IMwpf4AlgFvApuBL5a6nnE8rssImpJrgTXhxzKC/teVwMbw87RweyO4omsz8CuCq0RKfhwneOwfAJ4Kv54P/BLYBDwKlIXrk+HypvD1+aWu+ySOdzHQEp7rfwbqJvN5Bv4CeANYB/xfoGwynmfgEYJxlkGClsCnTuS8AreHx78JuO14atCjNkREpKCp3sUkIiKjUECIiEhBCggRESlIASEiIgUpIEREpCAFhEjIzF4IP88zs98a5/f+s0LfS+RUpstcRUYwsw8Af+Lu1x/HPlF3zx7l9W53rxyP+kQmiloQIiEz6w6/vAd4n5mtCeceiJrZ35jZqvBZ+78Xbv8BC+bc+CHBzUmY2T+b2epwvoLl4bp7gFT4fg/nf6/wzte/Cec2+JWZfSzvvf/TDs3z8HB45zBmdo+ZvR7W8vWJ/BnJ1BI79iYiU86d5LUgwl/0B9z93WZWBvy3mT0XbrsUWOTub4XLt7t7u5mlgFVm9ri732lmn3H3xQW+10cI7oS+AJgR7vPz8LULgV8jeHbOfwOXmtnrwK8D57q7m1ntuB+9SEgtCJFju4bgOTdrCB6ZPp1gYhaAX+aFA8AfmdmrwIsED0lbwNFdBjzi7ll33wM8D7w7771b3T1H8KiUeUAX0A88YGYfAXpP+uhERqGAEDk2A+5w98Xhx5nuPtSC6BneKBi7+CDBBDUXAK8QPAvoWO89moG8r7MEE+JkCFotjwM3Ac8c15GIHAcFhMiRDgJVecvPAn8QPj4dMzsnnJRnpBqC6S17zexcgqlehwwO7T/Cz4GPheMc9cDlBA+VKyic36PG3Z8GPkvQPSVSFBqDEDnSWiATdhV9n2DO53nAy+FAcRvBX+8jPQP8vpmtJZjy8cW81+4H1prZyx48hnzIEwRTZL5K8PTdL7j77jBgCqkCfmZmSYLWx+dO7BBFjk2XuYqISEHqYhIRkYIUECIiUpACQkREClJAiIhIQQoIEREpSAEhIiIFKSBERKSg/w/pUV1JV/zJlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "epsilon = np.float(1e-100)\n",
    "\n",
    "# Sigmoid Function\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "# Predict Function\n",
    "def predict(X, W):\n",
    "    return (np.dot(X,W))\n",
    "\n",
    "# Cross-entropy loss function\n",
    "def cross_entropy_loss(H, Y):\n",
    "    Y = np.array(Y)\n",
    "    return (-Y * np.log(H + epsilon) - (1 - Y) * np.log(1 - H + epsilon)).mean()\n",
    "\n",
    "# Function to convert probabilities back into class labels\n",
    "def to_classlabel(z):\n",
    "    return z.argmax(axis=1)\n",
    "\n",
    "# Mini-batch Gradient Descent with batch size of 32 samples\n",
    "def miniBatchGD(X, Y, ytr_enc, alpha, iters, batch_size = 32):\n",
    "    \n",
    "    m = (X.shape)[0]\n",
    "    n = (X.shape)[1] \n",
    "    W = np.full((n, 2), 0.1) # n x 3\n",
    "    inner_iters = math.floor(m/batch_size)\n",
    "    cost_ = []\n",
    "\n",
    "    for epoch in range (iters):\n",
    "        for i in range(inner_iters):\n",
    "\n",
    "            # Splitting data into batches\n",
    "            b = i * 32\n",
    "            batchX = X[b : b + 32]\n",
    "            batchY = Y[b : b + 32]\n",
    "\n",
    "            # Performing Gradient descent on the current batch and updating weights accordingly\n",
    "            H = predict(batchX, W)\n",
    "            sigm = sigmoid(H) \n",
    "            diff = sigm - batchY\n",
    "            grad = np.dot(batchX.T, diff)\n",
    "            W -= (alpha * grad)\n",
    "        \n",
    "        # Finding cost after each iteration\n",
    "        H = predict(X, W)\n",
    "        sigm = sigmoid(H)\n",
    "        predicted = to_classlabel(sigm)\n",
    "        cost_.append(cross_entropy_loss(predicted, ytr_enc))\n",
    "\n",
    "    return W, cost_\n",
    "\n",
    "epoch = 1000\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "W_lr, cost_ = miniBatchGD(vecxtr,ytr,ytr_enc,0.001,epoch)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Plotting cost against number of iterations\n",
    "epochs = np.arange(1, epoch+1)\n",
    "plt.plot(epochs, cost_)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-byYu4Fdv9L"
   },
   "source": [
    "### 3.2 k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8P9ZRIeAdv9T",
    "outputId": "3a40f7ac-e848-463b-bc44-80648999c2f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 687.3358438014984 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate cosine similarity between two vectors\n",
    "def cosine_similarity(P, Q):\n",
    "    return np.dot(P, Q)/(np.linalg.norm(P)*np.linalg.norm(Q))\n",
    "\n",
    "# K Nearest Neighbours Function\n",
    "def KNN(xtr, xte, ytr, k):\n",
    "    pred = []\n",
    "\n",
    "    # Iterating through the test data\n",
    "    for test in xte: \n",
    "\n",
    "        # Finding the cosine similarity with entire train data\n",
    "        d = list(map(lambda train: cosine_similarity(train, test), xtr)) \n",
    "\n",
    "        # Adding the correct label next to each distance by makeing a tuple\n",
    "        di = np.array(list(zip(d, ytr)))\n",
    "\n",
    "        # Taking only the maximum k distance tuples\n",
    "        idx = np.argpartition(di[:, 0], k)\n",
    "        nearest_k = di[idx[::-1][:k]]\n",
    "\n",
    "        # Extracting the labels only\n",
    "        nearest_k = nearest_k[:,1] \n",
    "\n",
    "        # Finding the mode value for the predicts\n",
    "        try: \n",
    "            most_common = mode(nearest_k) \n",
    "            \n",
    "        # Handling the ties by backing off to k-1 neighbors\n",
    "        except:\n",
    "            most_common = mode(nearest_k[:k-1])\n",
    "        pred.append(most_common)\n",
    "\n",
    "    pred = [int(i) for i in pred]\n",
    "    return pred\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Running for k = 1\n",
    "k_1 = KNN(vecxtr, vecxte, ytr_enc, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 703.5744471549988 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Running for k = 3\n",
    "start_time = time.time()\n",
    "k_3 = KNN(vecxtr, vecxte, ytr_enc, 3)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 702.2141370773315 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Running for k = 5\n",
    "start_time = time.time()\n",
    "k_5 = KNN(vecxtr, vecxte, ytr_enc, 5)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 701.5105111598969 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Running for k = 7\n",
    "start_time = time.time()\n",
    "k_7 = KNN(vecxtr, vecxte, ytr_enc, 7)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 714.2522234916687 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Running for k = 10\n",
    "start_time = time.time()\n",
    "k_10 = KNN(vecxtr, vecxte, ytr_enc, 10)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c01ZVoAhdv9b"
   },
   "source": [
    "### 2.3 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vNEZ2fxFdv9d",
    "outputId": "b7d4a7aa-cbf8-4c57-ceb3-87339077f2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 441.82872319221497 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis function\n",
    "def hypothesis(X, thetas):\n",
    "    Z = np.dot(X, thetas.T).reshape(-1,1)\n",
    "    return Z\n",
    "\n",
    "# Prediction function that predict whether the label is -1 or 1 for test set using learned perceptron weights\n",
    "def predict_p(X, thetas):\n",
    "    H = hypothesis(X, thetas)\n",
    "    predictions = []\n",
    "    for i in range(len(H)):\n",
    "        if H[i] > 0:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    predictions = np.array(predictions).reshape(-1,1)\n",
    "    return predictions\n",
    "\n",
    "# Perceptron learning algorithm\n",
    "def perceptron(X, Y, epoch = 10):\n",
    "\n",
    "    # Initializing weights with some noise\n",
    "    w = np.random.rand(1, X.shape[1]+1)\n",
    "  \n",
    "    for epoch in range(epoch):\n",
    "        misclassified = 0\n",
    "        \n",
    "        # Looping over each (data, label) pair in the dataset\n",
    "        for x, y in zip(X, Y):\n",
    "            x = np.insert(x, 0, 1)\n",
    "\n",
    "            # Checks if pair (x_i, y_i) is misclassified\n",
    "            if y * np.dot(w, x.T) <= 0:\n",
    "\n",
    "                # Updates eights\n",
    "                w += (y * x)\n",
    "\n",
    "                # Increments the number of misclassification\n",
    "                misclassified += 1\n",
    "\n",
    "        # Breaks out of loop if no value is misclassified\n",
    "        if misclassified == 0:\n",
    "            break\n",
    "\n",
    "    return w\n",
    "\n",
    "# Converting X train into a matrix             \n",
    "xtr_p = np.asmatrix(vecxtr, dtype = 'float64')\n",
    "\n",
    "# Changing class labels from [0, 1] to [-1, 1]\n",
    "ytr_p = [-1 if i == 0 else 1 for i in ytr_enc]\n",
    "\n",
    "epoch = 1000\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "W_p = perceptron(xtr_p, ytr_p, epoch)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEHZCYzBdv9h"
   },
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8RiElvKdv9i"
   },
   "outputs": [],
   "source": [
    "def eval(prediction, expected):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for E, P in zip(expected, prediction):\n",
    "        if E == 0:\n",
    "            if P == E:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        if E == 1:\n",
    "            if P == E:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "    #Confusion Matrix\n",
    "    CM = np.array([[tp, fp],[fn, tn]])\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(tp, fp)\n",
    "    print(fn, tp)\n",
    "\n",
    "    #Precision\n",
    "    precision = float(tp) / float(tp + fp)\n",
    "    print(\"Precision: \", precision)\n",
    "    \n",
    "    #Recall\n",
    "    recall = float(tp) / float(tp + fn)\n",
    "    print(\"Recall: \", recall)\n",
    "    \n",
    "    #Accuracy\n",
    "    accuracy = float(tp + tn) / float(tp + fn + tn + fp)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    \n",
    "    #F1 score\n",
    "    f1_score = (2 * precision * recall) / (precision + recall)\n",
    "    print(\"F1 Score: \", f1_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fx2sVsTNdv9q"
   },
   "source": [
    "### 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "woenC2QJdv9r",
    "outputId": "72d5399f-435b-4394-8a30-cb0fa4a24321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "1530 509\n",
      "550 1530\n",
      "Precision:  0.7503678273663561\n",
      "Recall:  0.7355769230769231\n",
      "Accuracy:  0.7451263537906138\n",
      "F1 Score:  0.742898761835397\n"
     ]
    }
   ],
   "source": [
    "ni = predict(vecxte,W_lr)\n",
    "sigm = sigmoid(ni)\n",
    "predicted = to_classlabel(sigm)\n",
    "eval(predicted, yte)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4uEz_MBdv91"
   },
   "source": [
    "### 4.2 k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "colab_type": "code",
    "id": "3AWDXc_Cdv92",
    "outputId": "45d56f2f-5fe8-4b1a-843e-fdb7522205b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n",
      "\n",
      "Confusion Matrix:\n",
      "2080 2075\n",
      "0 2080\n",
      "Precision:  0.5006016847172082\n",
      "Recall:  1.0\n",
      "Accuracy:  0.5006016847172082\n",
      "F1 Score:  0.6672012830793905\n",
      "\n",
      "K = 3\n",
      "\n",
      "Confusion Matrix:\n",
      "1968 1838\n",
      "112 1968\n",
      "Precision:  0.5170782974251182\n",
      "Recall:  0.9461538461538461\n",
      "Accuracy:  0.5306859205776173\n",
      "F1 Score:  0.6687054026503568\n",
      "\n",
      "K = 5\n",
      "\n",
      "Confusion Matrix:\n",
      "1995 1898\n",
      "85 1995\n",
      "Precision:  0.5124582584125353\n",
      "Recall:  0.9591346153846154\n",
      "Accuracy:  0.5227436823104693\n",
      "F1 Score:  0.6680060271220492\n",
      "\n",
      "K = 7\n",
      "\n",
      "Confusion Matrix:\n",
      "1982 1861\n",
      "98 1982\n",
      "Precision:  0.5157429091855321\n",
      "Recall:  0.9528846153846153\n",
      "Accuracy:  0.5285198555956678\n",
      "F1 Score:  0.6692554448759074\n",
      "\n",
      "K = 10\n",
      "\n",
      "Confusion Matrix:\n",
      "1938 1765\n",
      "142 1938\n",
      "Precision:  0.5233594382932757\n",
      "Recall:  0.9317307692307693\n",
      "Accuracy:  0.541034897713598\n",
      "F1 Score:  0.6702403596749092\n"
     ]
    }
   ],
   "source": [
    "print(\"K = 1\")\n",
    "eval(k_1, yte)\n",
    "print(\"\\nK = 3\")\n",
    "eval(k_3, yte)\n",
    "print(\"\\nK = 5\")\n",
    "eval(k_5, yte)\n",
    "print(\"\\nK = 7\")\n",
    "eval(k_7, yte)\n",
    "print(\"\\nK = 10\")\n",
    "eval(k_10, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqiGqT3udv97"
   },
   "source": [
    "### 4.3 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "1BOrjI9odv98",
    "outputId": "1a7b3500-19ee-4286-fa61-b4fcfead149b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "1934 1535\n",
      "146 1934\n",
      "Precision:  0.5575093686941481\n",
      "Recall:  0.9298076923076923\n",
      "Accuracy:  0.5954271961492178\n",
      "F1 Score:  0.697062533789872\n"
     ]
    }
   ],
   "source": [
    "xte_p = np.c_[ np.ones((vecxte.shape)[0]), vecxte ] \n",
    "predicted_p = predict_p(xte_p, W_p)\n",
    "eval(predicted_p, yte) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjy5B8zhplTi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "21100185_19100085.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
